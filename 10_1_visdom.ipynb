{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting up a new session...\n"
     ]
    }
   ],
   "source": [
    "import visdom\n",
    "vis = visdom.Visdom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_38774f359878fe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.text('Hello, World!', env='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_38774f6e34df5a'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(3, 200, 200)\n",
    "vis.image(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_38774f921cf146'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.images(torch.randn(3, 3, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root=\"data/MNIST/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=\"data/MNIST/\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/CIFAR10/cifar-10-python.tar.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e99e4afd7d748c19793d02ec4c4f98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/CIFAR10/cifar-10-python.tar.gz to data/CIFAR10/\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "cifar10_train = dsets.CIFAR10(root=\"data/CIFAR10/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "cifar10_test = dsets.CIFAR10(root=\"data/CIFAR10/\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_387750312b7bd2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = mnist_train.__getitem__(0)\n",
    "print(data[0].shape)\n",
    "vis.image(data[0], env='main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, \n",
    "                                          batch_size=32, \n",
    "                                          shuffle=True, \n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for num, (image, label) in enumerate(data_loader):\n",
    "#     value = value[0]\n",
    "    print(image.shape)\n",
    "    vis.images(image)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis.close(env='main')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_data = torch.randn(5) # n 개수에 상관없이 (0,1) 에 plot시킴\n",
    "plt = vis.line(Y=Y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = torch.Tensor([1,2,3,4,5])\n",
    "plt = vis.line(Y=Y_data, X=X_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## line update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'window_3877516671010e'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_append = torch.randn(1)\n",
    "X_append = torch.Tensor([6])\n",
    "vis.line(Y=Y_append, X=X_append, win=plt, update='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'window_387751ccc3b17a'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.Tensor(list(range(1,10+1)))\n",
    "print(X.shape)\n",
    "vis.line(Y=torch.randn(10,2), X=X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_tracker(loss_plot, loss_value, x):\n",
    "    vis.line(X=x, Y=loss_value, win=loss_plot, update='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Connection is already closed.\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n",
      "[Errno 111] Connection refused\n"
     ]
    }
   ],
   "source": [
    "# plt = vis.line(Y=torch.Tensor(1).zero_(), opts = dict(title='loss', legend=['1번'], showlegend=True))\n",
    "plt = vis.line(Y=torch.Tensor([0]), opts = dict(title='sample', legend=['loss'], showlegend=True))\n",
    "\n",
    "for i in range(500):\n",
    "    loss = torch.randn(1) + 0.1*i\n",
    "    loss_tracker(plt, loss, torch.Tensor([i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_huggingface",
   "language": "python",
   "name": "pytorch_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
