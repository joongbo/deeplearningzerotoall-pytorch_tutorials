{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_data  train_data\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/custom_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((64,128))\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='data/custom_data/raw_data/', transform=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF3C8> 0\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF438> 0\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF2E8> 0\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF390> 0\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF4A8> 0\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B2207D68> 1\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF400> 1\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20E7F28> 1\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20E7DD8> 1\n",
      "<PIL.Image.Image image mode=RGB size=128x64 at 0x7F86B20DF470> 1\n"
     ]
    }
   ],
   "source": [
    "for num, (data, label) in enumerate(train_data):\n",
    "    print(data, label)\n",
    "#     imshow(data)\n",
    "    \n",
    "    if(label == 1):\n",
    "        data.save('data/custom_data/train_data/scene/{}_{}.jpg'.format(num, label))\n",
    "    else:\n",
    "        data.save('data/custom_data/train_data/portrait/{}_{}.jpg'.format(num, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train model with custom data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu' # 'cpu' or 'cuda'?\n",
    "torch.manual_seed(1)\n",
    "# torch.cuda.manual_seed_all(1)\n",
    "\n",
    "training_epochs = 50\n",
    "batch_size = 2\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.ImageFolder(root='data/custom_data/train_data/', \n",
    "                                              transform=trans)\n",
    "\n",
    "data_loader = torch.utils.data.DataLoader(dataset=train_data, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__() # CNN, self 안하면 학습이 안돼요? 아뇨 멀쩡히 돼요..\n",
    "        #(1,28,28)\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        #(8,14,14)\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        #(64,7,7)\n",
    "        self.fc = nn.Linear(16*13*29, 2, bias=True)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out # 이거 안하면 또 안돌아가.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CNN().to(device)\n",
    "test_input = (torch.Tensor(3,3,64,128)).to(device)\n",
    "test_out = net(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss().to(device)\n",
    "# loss_func = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:0] cost = 0.7317471504211426\n",
      "[Epoch:1] cost = 0.6577640771865845\n",
      "[Epoch:2] cost = 0.5712885856628418\n",
      "[Epoch:3] cost = 0.4488232135772705\n",
      "[Epoch:4] cost = 0.31133317947387695\n",
      "[Epoch:5] cost = 0.1864018738269806\n",
      "[Epoch:6] cost = 0.07658257335424423\n",
      "[Epoch:7] cost = 0.048014264553785324\n",
      "[Epoch:8] cost = 0.022109946236014366\n",
      "[Epoch:9] cost = 0.046676427125930786\n",
      "[Epoch:10] cost = 0.012096637859940529\n",
      "[Epoch:11] cost = 0.011128216050565243\n",
      "[Epoch:12] cost = 0.0023021474480628967\n",
      "[Epoch:13] cost = 0.0032826457172632217\n",
      "[Epoch:14] cost = 0.0022370803635567427\n",
      "[Epoch:15] cost = 0.0007091190200299025\n",
      "[Epoch:16] cost = 0.00048009888269007206\n",
      "[Epoch:17] cost = 0.00028503540670499206\n",
      "[Epoch:18] cost = 0.0002766147954389453\n",
      "[Epoch:19] cost = 0.000259283056948334\n",
      "[Epoch:20] cost = 0.0002476434165146202\n",
      "[Epoch:21] cost = 0.00023943539417814463\n",
      "[Epoch:22] cost = 0.00022766494657844305\n",
      "[Epoch:23] cost = 0.00021765957353636622\n",
      "[Epoch:24] cost = 0.00020581674471031874\n",
      "[Epoch:25] cost = 0.00019456962763797492\n",
      "[Epoch:26] cost = 0.00018905228353105485\n",
      "[Epoch:27] cost = 0.0001809614332159981\n",
      "[Epoch:28] cost = 0.00017639779252931476\n",
      "[Epoch:29] cost = 0.00017157188267447054\n",
      "[Epoch:30] cost = 0.00016619788948446512\n",
      "[Epoch:31] cost = 0.0001626110024517402\n",
      "[Epoch:32] cost = 0.00015978686860762537\n",
      "[Epoch:33] cost = 0.0001552352769067511\n",
      "[Epoch:34] cost = 0.00015233943122439086\n",
      "[Epoch:35] cost = 0.00014819214993622154\n",
      "[Epoch:36] cost = 0.00014381876098923385\n",
      "[Epoch:37] cost = 0.00013979108189232647\n",
      "[Epoch:38] cost = 0.00013618086813949049\n",
      "[Epoch:39] cost = 0.00013576383935287595\n",
      "[Epoch:40] cost = 0.0001299016148550436\n",
      "[Epoch:41] cost = 0.00012722055544145405\n",
      "[Epoch:42] cost = 0.00012270432489458472\n",
      "[Epoch:43] cost = 0.00012100009189452976\n",
      "[Epoch:44] cost = 0.00011852118041133508\n",
      "[Epoch:45] cost = 0.00011507744784466922\n",
      "[Epoch:46] cost = 0.00011337311298120767\n",
      "[Epoch:47] cost = 0.00010997695062542334\n",
      "[Epoch:48] cost = 0.0001070930520654656\n",
      "[Epoch:49] cost = 0.00010499544441699982\n"
     ]
    }
   ],
   "source": [
    "total_batch = len(data_loader)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.0\n",
    "    for num, (imgs, labels) in enumerate(data_loader):\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        out = net(imgs)\n",
    "        loss = loss_func(out, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += loss / total_batch\n",
    "        \n",
    "    print('[Epoch:{}] cost = {}'.format(epoch, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model save and load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), \"./model/model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_net = CNN().to(device)\n",
    "new_net.load_state_dict(torch.load(\"./model/model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "print(net.layer1[0])\n",
    "print(new_net.layer1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0800, -0.0312, -0.0076,  0.0680, -0.0973], grad_fn=<SelectBackward>)\n",
      "tensor([ 0.0800, -0.0312, -0.0076,  0.0680, -0.0973], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(net.layer1[0].weight[0][0][0])\n",
    "print(new_net.layer1[0].weight[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]],\n",
       "\n",
       "        [[True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True],\n",
       "         [True, True, True, True, True]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.layer1[0].weight[0] == new_net.layer1[0].weight[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_huggingface",
   "language": "python",
   "name": "pytorch_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
