{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = dsets.MNIST(root=\"data/MNIST/\", train=True, transform=transforms.ToTensor(), download=True)\n",
    "mnist_test = dsets.MNIST(root=\"data/MNIST/\", train=False, transform=transforms.ToTensor(), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True, \n",
    "                                          drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/15 Cost: 4.646300 Accuracy: 63.53%\n",
      "Epoch: 0002/15 Cost: 1.489968 Accuracy: 76.58%\n",
      "Epoch: 0003/15 Cost: 1.021626 Accuracy: 81.46%\n",
      "Epoch: 0004/15 Cost: 0.823346 Accuracy: 84.05%\n",
      "Epoch: 0005/15 Cost: 0.707713 Accuracy: 85.61%\n",
      "Epoch: 0006/15 Cost: 0.631166 Accuracy: 86.80%\n",
      "Epoch: 0007/15 Cost: 0.575449 Accuracy: 87.58%\n",
      "Epoch: 0008/15 Cost: 0.533720 Accuracy: 87.74%\n",
      "Epoch: 0009/15 Cost: 0.501321 Accuracy: 87.82%\n",
      "Epoch: 0010/15 Cost: 0.475027 Accuracy: 88.23%\n",
      "Epoch: 0011/15 Cost: 0.453282 Accuracy: 88.59%\n",
      "Epoch: 0012/15 Cost: 0.435329 Accuracy: 88.75%\n",
      "Epoch: 0013/15 Cost: 0.419511 Accuracy: 88.33%\n",
      "Epoch: 0014/15 Cost: 0.406036 Accuracy: 88.54%\n",
      "Epoch: 0015/15 Cost: 0.394308 Accuracy: 89.01%\n"
     ]
    }
   ],
   "source": [
    "device = 'cpu' # 'cpu' or 'cuda'?\n",
    "linear = torch.nn.Linear(28 * 28, 10, bias=True).to(device)\n",
    "torch.nn.init.normal_(linear.weight)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(linear.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    with torch.no_grad():\n",
    "        X_test = mnist_test.data.view(-1, 28 * 28).float().to(device) # data <-- test_data\n",
    "        Y_test = mnist_test.targets.to(device) # targets <-- test_labels\n",
    "\n",
    "        prediction = linear(X_test)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "    print(\"Epoch: {:04d}/{} Cost: {:.6f} Accuracy: {:.2f}%\".format(epoch + 1, training_epochs, avg_cost, accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mlp with relu and cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/15 cost = 148.772842\n",
      "Epoch: 0002/15 cost = 35.280933\n",
      "Epoch: 0003/15 cost = 22.122944\n",
      "Epoch: 0004/15 cost = 15.287751\n",
      "Epoch: 0005/15 cost = 11.041275\n",
      "Epoch: 0006/15 cost = 8.200020\n",
      "Epoch: 0007/15 cost = 6.009705\n",
      "Epoch: 0008/15 cost = 4.554917\n",
      "Epoch: 0009/15 cost = 3.447356\n",
      "Epoch: 0010/15 cost = 2.445161\n",
      "Epoch: 0011/15 cost = 1.934303\n",
      "Epoch: 0012/15 cost = 1.445817\n",
      "Epoch: 0013/15 cost = 1.059533\n",
      "Epoch: 0014/15 cost = 0.868608\n",
      "Epoch: 0015/15 cost = 0.696072\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' # 'cpu' or 'cuda'?\n",
    "linear1 = torch.nn.Linear(28 * 28, 256, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True).to(device)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True).to(device)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "torch.nn.init.normal_(linear1.weight)\n",
    "torch.nn.init.normal_(linear2.weight)\n",
    "torch.nn.init.normal_(linear3.weight)\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print(\"Epoch: {:04d}/{} cost = {:.6f}\".format(epoch + 1, training_epochs, avg_cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9532999992370605\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    X_test = mnist_test.data.view(-1, 28 * 28).float().to(device) # data <-- test_data\n",
    "    Y_test = mnist_test.targets.to(device) # targets <-- test_labels\n",
    "    \n",
    "    prediction = model(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print(\"Accuracy: \", accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## initialization Xavier / He"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/15 Cost: 0.241805 Accuracy: 96.56%\n",
      "Epoch: 0002/15 Cost: 0.092317 Accuracy: 97.58%\n",
      "Epoch: 0003/15 Cost: 0.060258 Accuracy: 97.59%\n",
      "Epoch: 0004/15 Cost: 0.043647 Accuracy: 97.66%\n",
      "Epoch: 0005/15 Cost: 0.033376 Accuracy: 97.71%\n",
      "Epoch: 0006/15 Cost: 0.026777 Accuracy: 97.57%\n",
      "Epoch: 0007/15 Cost: 0.020749 Accuracy: 97.87%\n",
      "Epoch: 0008/15 Cost: 0.017008 Accuracy: 97.76%\n",
      "Epoch: 0009/15 Cost: 0.016517 Accuracy: 97.50%\n",
      "Epoch: 0010/15 Cost: 0.015579 Accuracy: 97.70%\n",
      "Epoch: 0011/15 Cost: 0.010295 Accuracy: 97.94%\n",
      "Epoch: 0012/15 Cost: 0.010483 Accuracy: 97.97%\n",
      "Epoch: 0013/15 Cost: 0.012657 Accuracy: 98.05%\n",
      "Epoch: 0014/15 Cost: 0.009605 Accuracy: 97.69%\n",
      "Epoch: 0015/15 Cost: 0.010982 Accuracy: 97.66%\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' # 'cpu' or 'cuda'?\n",
    "linear1 = torch.nn.Linear(28 * 28, 256, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(256, 256, bias=True).to(device)\n",
    "linear3 = torch.nn.Linear(256, 10, bias=True).to(device)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, linear2, relu, linear3).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    \n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        X_test = mnist_test.data.view(-1, 28 * 28).float().to(device) # data <-- test_data\n",
    "        Y_test = mnist_test.targets.to(device) # targets <-- test_labels\n",
    "\n",
    "        prediction = model(X_test)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "    print(\"Epoch: {:04d}/{} Cost: {:.6f} Accuracy: {:.2f}%\".format(epoch + 1, training_epochs, avg_cost, accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/15 Cost: 0.484289 Accuracy: 94.99%\n",
      "Epoch: 0002/15 Cost: 0.222181 Accuracy: 96.19%\n",
      "Epoch: 0003/15 Cost: 0.173728 Accuracy: 96.96%\n",
      "Epoch: 0004/15 Cost: 0.156650 Accuracy: 96.67%\n",
      "Epoch: 0005/15 Cost: 0.143594 Accuracy: 96.96%\n",
      "Epoch: 0006/15 Cost: 0.133348 Accuracy: 97.39%\n",
      "Epoch: 0007/15 Cost: 0.122592 Accuracy: 97.21%\n",
      "Epoch: 0008/15 Cost: 0.118362 Accuracy: 97.15%\n",
      "Epoch: 0009/15 Cost: 0.110881 Accuracy: 97.66%\n",
      "Epoch: 0010/15 Cost: 0.107140 Accuracy: 97.66%\n",
      "Epoch: 0011/15 Cost: 0.102363 Accuracy: 97.70%\n",
      "Epoch: 0012/15 Cost: 0.100835 Accuracy: 97.86%\n",
      "Epoch: 0013/15 Cost: 0.097960 Accuracy: 97.68%\n",
      "Epoch: 0014/15 Cost: 0.093695 Accuracy: 97.56%\n",
      "Epoch: 0015/15 Cost: 0.093288 Accuracy: 97.81%\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' # 'cpu' or 'cuda'?\n",
    "linear1 = torch.nn.Linear(28 * 28, 512, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(512, 512, bias=True).to(device)\n",
    "linear3 = torch.nn.Linear(512, 512, bias=True).to(device)\n",
    "linear4 = torch.nn.Linear(512, 512, bias=True).to(device)\n",
    "linear5 = torch.nn.Linear(512, 10, bias=True).to(device)\n",
    "relu = torch.nn.ReLU()\n",
    "dropout = torch.nn.Dropout(p=0.5)\n",
    "\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)\n",
    "\n",
    "model = torch.nn.Sequential(linear1, relu, dropout, \n",
    "                            linear2, relu, dropout, \n",
    "                            linear3, relu, dropout,\n",
    "                            linear4, relu, dropout,\n",
    "                            linear5).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "    model.train()\n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        X_test = mnist_test.data.view(-1, 28 * 28).float().to(device) # data <-- test_data\n",
    "        Y_test = mnist_test.targets.to(device) # targets <-- test_labels\n",
    "\n",
    "        prediction = model(X_test)\n",
    "        correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "        accuracy = correct_prediction.float().mean()\n",
    "    print(\"Epoch: {:04d}/{} Cost: {:.6f} Accuracy: {:.2f}%\".format(epoch + 1, training_epochs, avg_cost, accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batchnormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001/15 BN_Accuracy: 94.53% /  NN_Accuracy: 93.10%\n",
      "Epoch: 0002/15 BN_Accuracy: 95.96% /  NN_Accuracy: 94.03%\n",
      "Epoch: 0003/15 BN_Accuracy: 96.50% /  NN_Accuracy: 95.57%\n",
      "Epoch: 0004/15 BN_Accuracy: 96.74% /  NN_Accuracy: 95.46%\n",
      "Epoch: 0005/15 BN_Accuracy: 96.97% /  NN_Accuracy: 96.18%\n",
      "Epoch: 0006/15 BN_Accuracy: 96.89% /  NN_Accuracy: 96.47%\n",
      "Epoch: 0007/15 BN_Accuracy: 97.00% /  NN_Accuracy: 96.72%\n",
      "Epoch: 0008/15 BN_Accuracy: 97.01% /  NN_Accuracy: 96.67%\n",
      "Epoch: 0009/15 BN_Accuracy: 97.26% /  NN_Accuracy: 96.69%\n",
      "Epoch: 0010/15 BN_Accuracy: 97.15% /  NN_Accuracy: 96.84%\n",
      "Epoch: 0011/15 BN_Accuracy: 96.95% /  NN_Accuracy: 96.80%\n",
      "Epoch: 0012/15 BN_Accuracy: 97.14% /  NN_Accuracy: 96.90%\n",
      "Epoch: 0013/15 BN_Accuracy: 97.19% /  NN_Accuracy: 96.75%\n",
      "Epoch: 0014/15 BN_Accuracy: 97.15% /  NN_Accuracy: 96.38%\n",
      "Epoch: 0015/15 BN_Accuracy: 97.20% /  NN_Accuracy: 97.16%\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' # 'cpu' or 'cuda'?\n",
    "linear1 = torch.nn.Linear(28 * 28, 32, bias=True).to(device)\n",
    "linear2 = torch.nn.Linear(32, 32, bias=True).to(device)\n",
    "linear3 = torch.nn.Linear(32, 10, bias=True).to(device)\n",
    "relu = torch.nn.ReLU()\n",
    "bn1 = torch.nn.BatchNorm1d(num_features=32) # gamma and beta\n",
    "bn2 = torch.nn.BatchNorm1d(num_features=32)\n",
    "\n",
    "torch.nn.init.xavier_uniform_(linear1.weight)\n",
    "torch.nn.init.xavier_uniform_(linear2.weight)\n",
    "torch.nn.init.xavier_uniform_(linear3.weight)\n",
    "\n",
    "bn_model = torch.nn.Sequential(linear1, bn1, relu,\n",
    "                               linear2, bn2, relu,\n",
    "                               linear3).to(device)\n",
    "\n",
    "bn_optimizer = torch.optim.Adam(bn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "linear4 = torch.nn.Linear(28 * 28, 32, bias=True).to(device)\n",
    "linear5 = torch.nn.Linear(32, 32, bias=True).to(device)\n",
    "linear6 = torch.nn.Linear(32, 10, bias=True).to(device)\n",
    "relu = torch.nn.ReLU()\n",
    "\n",
    "torch.nn.init.xavier_uniform_(linear4.weight)\n",
    "torch.nn.init.xavier_uniform_(linear5.weight)\n",
    "torch.nn.init.xavier_uniform_(linear6.weight)\n",
    "\n",
    "nn_model = torch.nn.Sequential(linear4, relu,\n",
    "                               linear5, relu,\n",
    "                               linear6).to(device)\n",
    "\n",
    "nn_optimizer = torch.optim.Adam(nn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    model.train()\n",
    "    for X, Y in data_loader:\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        bn_hypothesis = bn_model(X)\n",
    "        bn_cost = criterion(bn_hypothesis, Y)\n",
    "        bn_optimizer.zero_grad()\n",
    "        bn_cost.backward()\n",
    "        bn_optimizer.step()\n",
    "        \n",
    "        nn_hypothesis = nn_model(X)\n",
    "        nn_cost = criterion(nn_hypothesis, Y)\n",
    "        nn_optimizer.zero_grad()\n",
    "        nn_cost.backward()\n",
    "        nn_optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        X_test = mnist_test.data.view(-1, 28 * 28).float().to(device) # data <-- test_data\n",
    "        Y_test = mnist_test.targets.to(device) # targets <-- test_labels\n",
    "\n",
    "        bn_prediction = bn_model(X_test)\n",
    "        bn_correct_prediction = torch.argmax(bn_prediction, 1) == Y_test\n",
    "        bn_accuracy = bn_correct_prediction.float().mean()\n",
    "        \n",
    "        nn_prediction = nn_model(X_test)\n",
    "        nn_correct_prediction = torch.argmax(nn_prediction, 1) == Y_test\n",
    "        nn_accuracy = nn_correct_prediction.float().mean()\n",
    "    print(\"Epoch: {:04d}/{} BN_Accuracy: {:.2f}% /  NN_Accuracy: {:.2f}%\".format(\n",
    "        epoch + 1, training_epochs, bn_accuracy.item() * 100, nn_accuracy.item() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_huggingface",
   "language": "python",
   "name": "pytorch_huggingface"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
